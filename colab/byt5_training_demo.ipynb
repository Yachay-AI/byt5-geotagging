{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X_jgK8JGQjD",
        "outputId": "ddf4d4cc-5784-4afd-e771-6ea293e41237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'byt5-geotagging'...\n",
            "remote: Enumerating objects: 226, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 226 (delta 46), reused 11 (delta 8), pack-reused 146\u001b[K\n",
            "Receiving objects: 100% (226/226), 13.02 MiB | 18.02 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary modules\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import torch\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa4vndBrimra",
        "outputId": "1ed8208e-3f6d-43cd-c71f-32ef868f41d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2EsT4lghapg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Clone the repository for geotagging with BYT5\n",
        "!git clone https://github.com/Yachay-AI/byt5-geotagging\n",
        "\n",
        "# Install required packages\n",
        "!pip install transformers==4.29.1 tqdm==4.63.2 pandas==1.4.4 wandb\n",
        "\n",
        "# Install gdown for Google Drive downloads\n",
        "!pip install gdown\n",
        "\n",
        "# Download the dataset\n",
        "!gdown https://drive.google.com/u/2/uc?id=1thkE-hgT3sDtZqILZH17Hyayy0hkk_jh&export=download\n",
        "\n",
        "# Unzip the downloaded dataset\n",
        "!tar xvf challenge_1.tar.gz > /dev/null\n",
        "\n",
        "# Read sample data\n",
        "!head data_sample_lc/c_46.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad1kJoI4hcVB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize an empty list to hold dataframes\n",
        "df_list = []\n",
        "\n",
        "# Loop through each JSON file and append it to df_list\n",
        "for fn in os.listdir(\"data_sample_lc\"):\n",
        "  df_list.append(pd.read_json(f\"data_sample_lc/{fn}\", lines=True))\n",
        "\n",
        "# Concatenate all dataframes in df_list\n",
        "df = pd.concat(df_list)\n",
        "\n",
        "# Extract latitude and longitude from 'coordinates' column\n",
        "df['lat'] = [x[1] for x in df['coordinates']]\n",
        "df['lon'] = [x[0] for x in df['coordinates']]\n",
        "\n",
        "# Drop the 'coordinates' column\n",
        "df.drop('coordinates', axis=1, inplace=True)\n",
        "\n",
        "# Shuffle the dataset\n",
        "df = df.sample(frac=1.0)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "df.iloc[:len(df)*9//10].to_csv('train.csv')\n",
        "df.iloc[len(df)*9//10:].to_csv('test.csv')\n",
        "\n",
        "# Count the number of lines in train.csv and test.csv\n",
        "!wc -l train.csv\n",
        "!wc -l test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7swmfDechfIn"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load cluster data\n",
        "cluster_df = pd.read_csv('byt5-geotagging/cluster_df.csv')\n",
        "\n",
        "# Save the clustering model\n",
        "with open('clustering.pkl', 'wb') as fout:\n",
        "  pickle.dump((cluster_df, []), fout)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZhJc7tshgcv",
        "outputId": "aab67305-7a8d-479f-9028-ede4650dcbde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:start\n",
            "start\n",
            "INFO:root:finish reading test file\n",
            "finish reading test file\n",
            "Warning, dropping 2 NaN rows\n",
            "INFO:root:finish reading train file\n",
            "finish reading train file\n",
            "INFO:root:Index(['Unnamed: 0', 'text', 'lat', 'lon', 'coordinates'], dtype='object')\n",
            "Index(['Unnamed: 0', 'text', 'lat', 'lon', 'coordinates'], dtype='object')\n",
            "Some weights of the model checkpoint at google/byt5-small were not used when initializing T5EncoderModel: ['decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.embed_tokens.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'lm_head.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.final_layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight']\n",
            "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:root:ByT5_classifier(\n",
            "  (byt5): T5EncoderModel(\n",
            "    (shared): Embedding(384, 1472)\n",
            "    (encoder): T5Stack(\n",
            "      (embed_tokens): Embedding(384, 1472)\n",
            "      (block): ModuleList(\n",
            "        (0): T5Block(\n",
            "          (layer): ModuleList(\n",
            "            (0): T5LayerSelfAttention(\n",
            "              (SelfAttention): T5Attention(\n",
            "                (q): Linear(in_features=1472, out_features=384, bias=False)\n",
            "                (k): Linear(in_features=1472, out_features=384, bias=False)\n",
            "                (v): Linear(in_features=1472, out_features=384, bias=False)\n",
            "                (o): Linear(in_features=384, out_features=1472, bias=False)\n",
            "                (relative_attention_bias): Embedding(32, 6)\n",
            "              )\n",
            "              (layer_norm): T5LayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (1): T5LayerFF(\n",
            "              (DenseReluDense): T5DenseGatedActDense(\n",
            "                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n",
            "                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n",
            "                (wo): Linear(in_features=3584, out_features=1472, bias=False)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "                (act): NewGELUActivation()\n",
            "              )\n",
            "              (layer_norm): T5LayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1-3): 3 x T5Block(\n",
            "          (layer): ModuleList(\n",
            "            (0): T5LayerSelfAttention(\n",
            "              (SelfAttention): T5Attention(\n",
            "                (q): Linear(in_features=1472, out_features=384, bias=False)\n",
            "                (k): Linear(in_features=1472, out_features=384, bias=False)\n",
            "                (v): Linear(in_features=1472, out_features=384, bias=False)\n",
            "                (o): Linear(in_features=384, out_features=1472, bias=False)\n",
            "              )\n",
            "              (layer_norm): T5LayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (1): T5LayerFF(\n",
            "              (DenseReluDense): T5DenseGatedActDense(\n",
            "                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n",
            "                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n",
            "                (wo): Linear(in_features=3584, out_features=1472, bias=False)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "                (act): NewGELUActivation()\n",
            "              )\n",
            "              (layer_norm): T5LayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (final_layer_norm): T5LayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (fc3): Linear(in_features=1472, out_features=3000, bias=True)\n",
            ")\n",
            "ByT5_classifier(\n",
            "  (byt5): T5EncoderModel(\n",
            "    (shared): Embedding(384, 1472)\n",
            "    (encoder): T5Stack(\n",
            "      (embed_tokens): Embedding(384, 1472)\n",
            "      (block): ModuleList(\n",
            "        (0): T5Block(\n",
            "          (layer): ModuleList(\n",
            "            (0): T5LayerSelfAttention(\n",
            "              (SelfAttention): T5Attention(\n",
            "                (q): Linear(in_features=1472, out_features=384, bias=False)\n",
            "                (k): Linear(in_features=1472, out_features=384, bias=False)\n",
            "                (v): Linear(in_features=1472, out_features=384, bias=False)\n",
            "                (o): Linear(in_features=384, out_features=1472, bias=False)\n",
            "                (relative_attention_bias): Embedding(32, 6)\n",
            "              )\n",
            "              (layer_norm): T5LayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (1): T5LayerFF(\n",
            "              (DenseReluDense): T5DenseGatedActDense(\n",
            "                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n",
            "                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n",
            "                (wo): Linear(in_features=3584, out_features=1472, bias=False)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "                (act): NewGELUActivation()\n",
            "              )\n",
            "              (layer_norm): T5LayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1-3): 3 x T5Block(\n",
            "          (layer): ModuleList(\n",
            "            (0): T5LayerSelfAttention(\n",
            "              (SelfAttention): T5Attention(\n",
            "                (q): Linear(in_features=1472, out_features=384, bias=False)\n",
            "                (k): Linear(in_features=1472, out_features=384, bias=False)\n",
            "                (v): Linear(in_features=1472, out_features=384, bias=False)\n",
            "                (o): Linear(in_features=384, out_features=1472, bias=False)\n",
            "              )\n",
            "              (layer_norm): T5LayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (1): T5LayerFF(\n",
            "              (DenseReluDense): T5DenseGatedActDense(\n",
            "                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n",
            "                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n",
            "                (wo): Linear(in_features=3584, out_features=1472, bias=False)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "                (act): NewGELUActivation()\n",
            "              )\n",
            "              (layer_norm): T5LayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (final_layer_norm): T5LayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (fc3): Linear(in_features=1472, out_features=3000, bias=True)\n",
            ")\n",
            "INFO:root:setting learning rate to 0.001\n",
            "setting learning rate to 0.001\n",
            "  0% 0/1500 [00:00<?, ?it/s]INFO:root:Epoch 0 training loss 8.00345516204834\n",
            "Epoch 0 training loss 8.00345516204834\n",
            "INFO:root:Epoch 0 eval loss 8.001379564404488  accuracy 0.0 true distance avg 8878.84765625 true distance median 9282.1728515625\n",
            "Epoch 0 eval loss 8.001379564404488  accuracy 0.0 true distance avg 8878.84765625 true distance median 9282.1728515625\n",
            "INFO:root:saved to models/byt5-class-0\n",
            "saved to models/byt5-class-0\n",
            "  3% 50/1500 [01:23<31:43,  1.31s/it]INFO:root:Epoch 0 training loss 7.60432580947876\n",
            "Epoch 0 training loss 7.60432580947876\n",
            "  7% 100/1500 [02:29<30:38,  1.31s/it]INFO:root:Epoch 0 training loss 7.259434833526611\n",
            "Epoch 0 training loss 7.259434833526611\n",
            " 10% 150/1500 [03:34<29:40,  1.32s/it]INFO:root:Epoch 0 training loss 7.156377630233765\n",
            "Epoch 0 training loss 7.156377630233765\n",
            " 13% 200/1500 [04:40<29:07,  1.34s/it]INFO:root:Epoch 0 training loss 7.005329895019531\n",
            "Epoch 0 training loss 7.005329895019531\n",
            " 17% 250/1500 [05:45<27:03,  1.30s/it]INFO:root:Epoch 0 training loss 6.96166690826416\n",
            "Epoch 0 training loss 6.96166690826416\n",
            " 20% 300/1500 [06:50<25:50,  1.29s/it]INFO:root:Epoch 0 training loss 6.751373910903931\n",
            "Epoch 0 training loss 6.751373910903931\n",
            " 23% 350/1500 [07:55<24:41,  1.29s/it]INFO:root:Epoch 0 training loss 6.622498903274536\n",
            "Epoch 0 training loss 6.622498903274536\n",
            " 27% 400/1500 [09:00<23:38,  1.29s/it]INFO:root:Epoch 0 training loss 6.479293766021729\n",
            "Epoch 0 training loss 6.479293766021729\n",
            " 30% 450/1500 [10:06<23:08,  1.32s/it]INFO:root:Epoch 0 training loss 6.399554300308227\n",
            "Epoch 0 training loss 6.399554300308227\n",
            " 33% 500/1500 [11:11<21:52,  1.31s/it]INFO:root:Epoch 0 training loss 6.393972873687744\n",
            "Epoch 0 training loss 6.393972873687744\n",
            "INFO:root:Epoch 0 eval loss 6.2446718364953995  accuracy 0.01611328125 true distance avg 6097.30615234375 true distance median 5450.4462890625\n",
            "Epoch 0 eval loss 6.2446718364953995  accuracy 0.01611328125 true distance avg 6097.30615234375 true distance median 5450.4462890625\n",
            "INFO:root:saved to models/byt5-class-0\n",
            "saved to models/byt5-class-0\n",
            " 37% 550/1500 [12:32<20:32,  1.30s/it]INFO:root:Epoch 0 training loss 6.282964744567871\n",
            "Epoch 0 training loss 6.282964744567871\n",
            " 40% 600/1500 [13:38<19:23,  1.29s/it]INFO:root:Epoch 0 training loss 6.223504056930542\n",
            "Epoch 0 training loss 6.223504056930542\n",
            " 43% 650/1500 [14:43<18:11,  1.28s/it]INFO:root:Epoch 0 training loss 6.22835033416748\n",
            "Epoch 0 training loss 6.22835033416748\n",
            " 47% 700/1500 [15:48<17:24,  1.31s/it]INFO:root:Epoch 0 training loss 6.191370840072632\n",
            "Epoch 0 training loss 6.191370840072632\n",
            " 50% 750/1500 [16:53<16:25,  1.31s/it]INFO:root:Epoch 0 training loss 6.1728477287292485\n",
            "Epoch 0 training loss 6.1728477287292485\n",
            " 53% 800/1500 [17:58<15:11,  1.30s/it]INFO:root:Epoch 0 training loss 6.13368670463562\n",
            "Epoch 0 training loss 6.13368670463562\n",
            " 57% 850/1500 [19:04<14:04,  1.30s/it]INFO:root:Epoch 0 training loss 6.110337629318237\n",
            "Epoch 0 training loss 6.110337629318237\n",
            " 60% 900/1500 [20:09<13:05,  1.31s/it]INFO:root:Epoch 0 training loss 6.011075067520141\n",
            "Epoch 0 training loss 6.011075067520141\n",
            " 63% 950/1500 [21:14<11:52,  1.30s/it]INFO:root:Epoch 0 training loss 6.032086563110352\n",
            "Epoch 0 training loss 6.032086563110352\n",
            " 67% 1000/1500 [22:19<10:42,  1.29s/it]INFO:root:Epoch 0 training loss 6.034633073806763\n",
            "Epoch 0 training loss 6.034633073806763\n",
            "INFO:root:Epoch 0 eval loss 5.95970506966114  accuracy 0.03076171875 true distance avg 5499.55126953125 true distance median 3286.312255859375\n",
            "Epoch 0 eval loss 5.95970506966114  accuracy 0.03076171875 true distance avg 5499.55126953125 true distance median 3286.312255859375\n",
            "INFO:root:saved to models/byt5-class-0\n",
            "saved to models/byt5-class-0\n",
            " 70% 1050/1500 [23:41<09:46,  1.30s/it]INFO:root:Epoch 0 training loss 5.958250713348389\n",
            "Epoch 0 training loss 5.958250713348389\n",
            " 73% 1100/1500 [24:46<08:34,  1.29s/it]INFO:root:Epoch 0 training loss 6.027169408798218\n",
            "Epoch 0 training loss 6.027169408798218\n",
            " 77% 1150/1500 [25:51<07:37,  1.31s/it]INFO:root:Epoch 0 training loss 6.092741241455078\n",
            "Epoch 0 training loss 6.092741241455078\n",
            " 80% 1200/1500 [26:56<06:34,  1.32s/it]INFO:root:Epoch 0 training loss 6.027866277694702\n",
            "Epoch 0 training loss 6.027866277694702\n",
            " 83% 1250/1500 [28:02<05:29,  1.32s/it]INFO:root:Epoch 0 training loss 6.05219033241272\n",
            "Epoch 0 training loss 6.05219033241272\n",
            " 87% 1300/1500 [29:07<04:21,  1.31s/it]INFO:root:Epoch 0 training loss 5.937793130874634\n",
            "Epoch 0 training loss 5.937793130874634\n",
            " 90% 1350/1500 [30:12<03:14,  1.30s/it]INFO:root:Epoch 0 training loss 5.95858850479126\n",
            "Epoch 0 training loss 5.95858850479126\n",
            " 93% 1400/1500 [31:17<02:09,  1.29s/it]INFO:root:Epoch 0 training loss 5.917217559814453\n",
            "Epoch 0 training loss 5.917217559814453\n",
            " 97% 1450/1500 [32:22<01:05,  1.30s/it]INFO:root:Epoch 0 training loss 5.936188411712647\n",
            "Epoch 0 training loss 5.936188411712647\n",
            "100% 1499/1500 [33:26<00:01,  1.30s/it]INFO:root:Epoch 0 eval loss 5.865092158317566  accuracy 0.03369140625 true distance avg 5523.3359375 true distance median 3205.36083984375\n",
            "Epoch 0 eval loss 5.865092158317566  accuracy 0.03369140625 true distance avg 5523.3359375 true distance median 3205.36083984375\n",
            "INFO:root:saved to models/byt5-class-0\n",
            "saved to models/byt5-class-0\n",
            "100% 1500/1500 [33:43<00:00,  1.35s/it]\n",
            "INFO:root:Epoch 0 training loss 5.952802872171207\n",
            "Epoch 0 training loss 5.952802872171207\n",
            "INFO:root:setting learning rate to 0.0001\n",
            "setting learning rate to 0.0001\n",
            "  0% 0/1500 [00:00<?, ?it/s]INFO:root:Epoch 1 training loss 5.873978614807129\n",
            "Epoch 1 training loss 5.873978614807129\n",
            "INFO:root:Epoch 1 eval loss 5.864679783582687  accuracy 0.03369140625 true distance avg 5537.39208984375 true distance median 3305.6572265625\n",
            "Epoch 1 eval loss 5.864679783582687  accuracy 0.03369140625 true distance avg 5537.39208984375 true distance median 3305.6572265625\n",
            "INFO:root:saved to models/byt5-class-1\n",
            "saved to models/byt5-class-1\n",
            "  3% 50/1500 [01:21<31:07,  1.29s/it]INFO:root:Epoch 1 training loss 5.938156929016113\n",
            "Epoch 1 training loss 5.938156929016113\n",
            "  7% 100/1500 [02:26<30:31,  1.31s/it]INFO:root:Epoch 1 training loss 5.84271201133728\n",
            "Epoch 1 training loss 5.84271201133728\n",
            " 10% 150/1500 [03:31<29:46,  1.32s/it]INFO:root:Epoch 1 training loss 5.807421417236328\n",
            "Epoch 1 training loss 5.807421417236328\n",
            " 13% 200/1500 [04:36<28:21,  1.31s/it]INFO:root:Epoch 1 training loss 5.8586264419555665\n",
            "Epoch 1 training loss 5.8586264419555665\n",
            " 17% 250/1500 [05:42<27:48,  1.33s/it]INFO:root:Epoch 1 training loss 5.830432386398315\n",
            "Epoch 1 training loss 5.830432386398315\n",
            " 17% 258/1500 [05:53<28:23,  1.37s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/byt5-geotagging/train_model.py\", line 535, in <module>\n",
            "    train_epoch_rel(epoch=epoch, model=model, training_generator=training_generator,\n",
            "  File \"/content/byt5-geotagging/train_model.py\", line 174, in train_epoch_rel\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 487, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 200, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run the training script\n",
        "# The parameters here are chosen to show a small training run on a small subset of data\n",
        "!python byt5-geotagging/train_model.py --train_input_file train.csv --test_input_file test.csv --do_train true --do_test true --load_clustering ./ --device cuda --batch_size 64 --keep_layer_count 4 --max_train 96000 --max_test 640\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDY5kaY7hhZl",
        "outputId": "ecf433a0-818a-4f92-e841-f1d576601c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:start\n",
            "start\n",
            "INFO:root:finish reading test file\n",
            "finish reading test file\n",
            "Warning, dropping 2 NaN rows\n",
            "INFO:root:finish reading train file\n",
            "finish reading train file\n",
            "INFO:root:Index(['Unnamed: 0', 'text', 'lat', 'lon', 'coordinates'], dtype='object')\n",
            "Index(['Unnamed: 0', 'text', 'lat', 'lon', 'coordinates'], dtype='object')\n",
            "INFO:root:model loaded\n",
            "model loaded\n",
            "100% 20/20 [00:05<00:00,  4.00it/s]\n",
            "INFO:root:Epoch 3 eval loss 5.908099246025086  accuracy 0.028125 true distance avg 5734.2490234375 true distance median 3978.244140625\n",
            "Epoch 3 eval loss 5.908099246025086  accuracy 0.028125 true distance avg 5734.2490234375 true distance median 3978.244140625\n",
            "INFO:root:threshold 0 MAE 5734.249003141335 Median 3978.2442709348024 percentage 1.0 acc 0.028125 precision 0.0984375 recall 1.0 f1@500 0.17923186344238975\n",
            "threshold 0 MAE 5734.249003141335 Median 3978.2442709348024 percentage 1.0 acc 0.028125 precision 0.0984375 recall 1.0 f1@500 0.17923186344238975\n",
            "/content/byt5-geotagging/train_model.py:252: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  part_true_distance_ls = pd.Series(part_true_distance_ls)\n",
            "/content/byt5-geotagging/train_model.py:268: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  f'acc {pd.Series(acc).mean()} ' +\n",
            "INFO:root:threshold 0.75 MAE nan Median nan percentage 0.0 acc nan precision 0 recall 0 f1@500 0\n",
            "threshold 0.75 MAE nan Median nan percentage 0.0 acc nan precision 0 recall 0 f1@500 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run the testing script\n",
        "# For demo purpose, a small subset of validation set is used\n",
        "!python byt5-geotagging/train_model.py --train_input_file train.csv --test_input_file test.csv --do_test true --load_clustering ./ --load_model_dir models/byt5-class-0 --device cuda --batch_size 32  --max_train 96000 --max_test 640\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDzMsI92htqN",
        "outputId": "f4f7d73e-1c0d-46ad-c51e-cff1630626e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/byt5-geotagging\n"
          ]
        }
      ],
      "source": [
        "cd byt5-geotagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRMdQXHEhiRA",
        "outputId": "06ea8e7c-2f47-494a-d9fe-d9c431cb5bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41.275721 -96.053431 0.018365390598773956\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load trained model and tokenizer\n",
        "device = 'cuda'\n",
        "byt5 = torch.load('../models/byt5-class-0')\n",
        "byt5_tokenizer = AutoTokenizer.from_pretrained('google/byt5-small')\n",
        "\n",
        "# Make a prediction\n",
        "text = 'I live in New York'\n",
        "inputs = byt5_tokenizer(text, return_tensors='pt')['input_ids'].unsqueeze(0)\n",
        "logits = byt5.to(device)(inputs.to(device))\n",
        "predicted_cluster = logits.argmax()\n",
        "confidence = torch.nn.functional.softmax(logits, dim=-1).max().item()\n",
        "predicted_location = cluster_df.iloc[predicted_cluster.item()]\n",
        "\n",
        "# Output predicted location and confidence\n",
        "print(predicted_location['lat'], predicted_location['lng'], confidence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljHoXvAOilvO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
